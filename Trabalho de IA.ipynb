{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7391e7d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToNumeric = [\"SeniorCitizen\",\n",
    "                    \"Partner\",\n",
    "                    \"Dependents\",\n",
    "                    \"PhoneService\",\n",
    "                    \"MultipleLines\",\n",
    "                    \"OnlineSecurity\",\n",
    "                    \"OnlineBackup\",\n",
    "                    \"DeviceProtection\",\n",
    "                    \"TechSupport\",\n",
    "                    \"StreamingTV\",\n",
    "                    \"StreamingMovies\",\n",
    "                    \"PaperlessBilling\",\n",
    "                    \"TotalCharges\",\n",
    "                    \"Churn\"] # Lista das colunas que terão seus tipos convertidos de object para numeric\n",
    "\n",
    "categoricalColumns = [\"gender\", \"Contract\", \"PaymentMethod\"]\n",
    "# Lista das colunas que vão passar pelo one-hot encoding\n",
    "\n",
    "numericalColumns = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = [\"gender\", \"Contract\", \"PaymentMethod\"]\n",
    "# Lista das colunas que vão passar pelo one-hot encoding\n",
    "\n",
    "numericalColumns = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "# Evita warning de que função replace mude dados de forma automática (downcasting)\n",
    "\n",
    "dataframe = pd.read_csv(\"customerchurn.csv\")\n",
    "# Definindo o Dataframe\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Definindo o StandardScaler para escalonar variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec951424",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"TotalCharges\"] = pd.to_numeric(dataframe[\"TotalCharges\"], errors=\"coerce\")\n",
    "# Converte os dados de TotalCharges para numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88641e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataframe.columns:\n",
    "    if dataframe[column].dtype == object:\n",
    "        dataframe[column] = dataframe[column].str.strip()\n",
    "        # Remove espaços em branco dos valores, cajo haja algum\n",
    "\n",
    "        dataframe[column] = dataframe[column].replace({\n",
    "            \"No phone service\": 0,\n",
    "            \"No\": 0,\n",
    "            \"Yes\": 1,\n",
    "            \"0\": 0,\n",
    "            \"1\": 1\n",
    "        }) # Troca valores por 0 ou 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[dataframe[\"TotalCharges\"].isnull(), \"TotalCharges\"] = 0\n",
    "# Preenche as linhas de TotalCharges nulas com 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columnsToNumeric:\n",
    "    dataframe[i] = pd.to_numeric(dataframe[i], errors=\"coerce\")\n",
    "    # Conversão de tipo para numeric\n",
    "\n",
    "    if i != \"TotalCharges\":\n",
    "        dataframe[i] = dataframe[i].astype(bool)\n",
    "        # \"Castando\" as colunas para tipo bool (exceto TotalCharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70271080",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.get_dummies(dataframe, columns=categoricalColumns, drop_first=False)\n",
    "# Aplica one-hot encoding para todas as colunas no categoricalColumns\n",
    "\n",
    "internet_dummies = pd.get_dummies(dataframe[\"InternetService\"], prefix=\"InternetService\", drop_first=True)\n",
    "# Aplica one-hot encoding apenas para a coluna InternetService, descartando a primeira coluna (No)\n",
    "\n",
    "dataframe = pd.concat([dataframe, internet_dummies], axis=1)\n",
    "# Adiciona as colunas dummies (one-hot encoding) no dataframe\n",
    "\n",
    "dataframe.drop(columns=[\"InternetService\"], inplace=True)\n",
    "# Remove a coluna original do dataframe, deixando apenas as que passaram pelo one-hot encoding\n",
    "\n",
    "dataframe[numericalColumns] = scaler.fit_transform(dataframe[numericalColumns])\n",
    "# Escalonamento de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"TotalCharges\"].hist(bins=30)\n",
    "plt.title(\"Distribuição de TotalCharges\")\n",
    "plt.xlabel(\"TotalCharges\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()\n",
    "# Histograma\n",
    "\n",
    "sb.boxplot(x=\"Churn\", y=\"MonthlyCharges\", data=dataframe)\n",
    "plt.title(\"Boxplot de MonthlyCharges por Churn\")\n",
    "plt.show()\n",
    "# Boxplot\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sb.heatmap(dataframe.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de correlação\")\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -- Seleção de Melhores Atributos via SelectKBest --- \n",
    "print(\"\\n--- Seleção de Features com SelectKBest ---\")\n",
    "\n",
    "# Separa as features (X) da variável alvo (y)\n",
    "# 'customerID' é removido pois não é uma feature de treinamento\n",
    "X = dataframe.drop(columns=['Churn', 'customerID'], errors='ignore')\n",
    "y = dataframe['Churn']\n",
    "\n",
    "# Seleciona as 20 melhores features\n",
    "k_best = 20\n",
    "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "X_best = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"As {k_best} melhores features selecionadas são:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31156fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aplicação de PCA para Visualização 2D --- \n",
    "print(\"\\n--- Visualização 2D com PCA ---\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X) # Usa o conjunto X completo\n",
    "\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['Componente Principal 1', 'Componente Principal 2'])\n",
    "pca_df['Churn'] = y.values\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sb.scatterplot(x='Componente Principal 1', y='Componente Principal 2', hue='Churn', data=pca_df, alpha=0.7)\n",
    "plt.title('Visualização 2D dos Clientes com PCA')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Churn')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c511f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay, roc_curve\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "# --- Dividir em treino e teste (80%/20%) ---\n",
    "print(\"\\n--- Divisão em Treino e Teste ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_best, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Shape de X_train: {X_train.shape}\")\n",
    "print(f\"Shape de X_test: {X_test.shape}\")\n",
    "print(f\"Shape de y_train: {y_train.shape}\")\n",
    "print(f\"Shape de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instânciamento dos modelos ---\n",
    "dt_model = DecisionTreeClassifier(random_state=42)  # Arvore de Decisão\n",
    "svm_model = SVC(random_state=42, probability=True) # SVM\n",
    "mlp_model = MLPClassifier(random_state=42, max_iter=2000) # MLP Rede Neural\n",
    "\n",
    "# Definir os parâmetros para GridSearchCV para cada modelo\n",
    "# Parâmetros da Árvore de Decisão\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "# Parâmetros do SVM\n",
    "param_grid_svm = {\n",
    "    'C': [1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "# Parâmetros do MLP Rede Neural\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100,)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d71f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Função para Calcular ROC-AUC ---\n",
    "def roc_auc_scoring_function(estimator, X, y_true):\n",
    "    # É necessário as probabilidades do modelo para criar a ROC-AUC\n",
    "    # Verifica se o modelo tem 'predict_proba'\n",
    "    if hasattr(estimator, 'predict_proba') and is_classifier(estimator):\n",
    "        y_proba = estimator.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        # Se não existir 'predict_proba', usamos a 'decision_function'\n",
    "        print(\"Aviso: predict_proba não disponivel\")\n",
    "        y_proba = estimator.predict(X)\n",
    "    return roc_auc_score(y_true, y_proba)\n",
    "\n",
    "# Agrupando modelos e seus parâmetros para o GridSearch\n",
    "models_to_tune = {\n",
    "    'Decision Tree': {'model': dt_model, 'params': param_grid_dt},\n",
    "    'SVM': {'model': svm_model, 'params': param_grid_svm},\n",
    "    'MLP': {'model': mlp_model, 'params': param_grid_mlp}\n",
    "}\n",
    "\n",
    "# Dicionário para apenas guardar o melhor modelo de cada tipo após o ajuste\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Realizar GridSearchCV para Ajuste de Hiperparâmetros ---\n",
    "print(\"\\n--- Ajuste de Hiperparâmetros com GridSearchCV ---\")\n",
    "for name, config in models_to_tune.items():\n",
    "    print(f\"\\nSintonizando o modelo: {name}...\")\n",
    "    grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring=roc_auc_scoring_function, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"\\n - Melhores parâmetros para {name}: {grid_search.best_params_}\")\n",
    "    print(f\" - Melhor pontuação ROC-AUC para {name} no treino (Validação Cruzada): {grid_search.best_score_:.4f}\")\n",
    "print(\"\\nTodos os modelos foram sintonizados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c76802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avaliar Desempenho no Conjunto de Teste ---\n",
    "print(\"\\n--- Avaliação dos Modelos no Conjunto Teste ---\")\n",
    "results = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\n--- Avaliando o modelo: {name} ---\")\n",
    "    y_pred = model.predict(X_test) # Faz as previsões binárias\n",
    "\n",
    "    # Obtem as probabilidades (scores) para a curva ROC e o ROC-AUC\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        # Probabilidade da classe positiva\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        #Score de decisão para SVM sem probabilidade=True\n",
    "        y_proba = model.decision_function(X_test)\n",
    "        print(f\"Aviso: {name} nâo tem predict_proba. Usando 'decision_function' para a curva ROC.\")\n",
    "\n",
    "    # --- Matriz de Confusão ---\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\n - Matriz de Confusão:\")\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(4, 3)) # Tamanho menor para a matriz de confusão\n",
    "    sb.heatmap(cm, annot=True, fmt = 'd', cmap='Blues', cbar=False) # cbar=False para remover a barra de cores\n",
    "    plt.title(f'Matriz de confusão - {name}')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Precision, Recall, F1-Score ---\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(report)\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) # Usamos a probabilidade para o melhor detalhamento\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Plotar Curvar ROC\n",
    "    plt.figure(figsize=(6, 5))\n",
    "\n",
    "    # Calcula a True Positive Rate (TPR) e False Positive Rate (FPR)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    # Plota a curva ROC\n",
    "    plt.plot(fpr, tpr, label=f'ROC {name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    # Plota a linha de base (classificados aleatório)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Classificador Aleatório')\n",
    "\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC - {name}')\n",
    "    plt.legend(loc='lower right') # Posição da legenda\n",
    "    plt.grid(True) # Adiciona uma grade no gráfico\n",
    "    plt.show() # Mostra o gráfico\n",
    "\n",
    "    results[name] = { # Armazena os resultados para um comparativo final\n",
    "        'Matriz de Confusão': cm,\n",
    "        'Relatório de Classificação': report,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "\n",
    "# Comparativo Final dos Modelos\n",
    "print(\"\\nAnalisando as pontuações ROC-AUC no conjunto de teste:\")\n",
    "print(\"\\n --- Análise Concluída ---\")\n",
    "for name, res in results.items():\n",
    "    print(f\" - {name}: ROC-AUC = {res['ROC-AUC']:.4f}\")\n",
    "print(\" -------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# Para este exemplo, criaremos um dataframe dummy para o código ser executável\n",
    "data = {\n",
    "    'customerID': [f'C{i}' for i in range(100)],\n",
    "    'Churn': [0, 1] * 50,\n",
    "    'MonthlyCharges': [i * 1.5 for i in range(100)],\n",
    "    'StreamingTV': [0, 1, 0, 1] * 25,\n",
    "    'StreamingMovies': [1, 0, 1, 0] * 25,\n",
    "    'PhoneService': [1] * 100,\n",
    "    'InternetService_DSL': [0, 1] * 50,\n",
    "    'InternetService_Fiber optic': [1, 0] * 50,\n",
    "    'TotalCharges': [i * 10 for i in range(100)]\n",
    "}\n",
    "dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Prepara os dados sem o churn\n",
    "# Remove a coluna churn e outras que não devem participar do clustering\n",
    "X_clustering = dataframe.drop(columns=['Churn', 'customerID', 'TotalCharges'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbbe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando valores para ver qual k tem o melhor score de silhueta\n",
    "for k in range(2, 10):\n",
    "    kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10) # Adicionado n_init\n",
    "    cluster_labels = kmeans_test.fit_predict(X_clustering)\n",
    "    sil_score = silhouette_score(X_clustering, cluster_labels)\n",
    "    print(f\"K={k} => Silhouette Score: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02462627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aplicar KMeans ---\n",
    "n_clusters = 3  # número de segmentos desejado\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10) # Adicionado n_init\n",
    "clusters = kmeans.fit_predict(X_clustering)\n",
    "\n",
    "# Avaliação de silhueta para decidir qual o melhor valor para k\n",
    "sil_score = silhouette_score(X_clustering, clusters)\n",
    "print(f\"\\nÍndice de Silhueta para {n_clusters} clusters: {sil_score:.4f}\")\n",
    "\n",
    "# Adiciona os rótulos dos clusters no dataframe original\n",
    "dataframe['Cluster'] = clusters\n",
    "\n",
    "print(\"\\n--- KMeans aplicado com sucesso ---\")\n",
    "print(\"Clientes agrupados nos seguintes clusters:\")\n",
    "print(dataframe['Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agrupamento e análise estatística por cluster ---\n",
    "cluster_analysis = dataframe.groupby('Cluster').agg({\n",
    "    'Churn': 'mean',\n",
    "    'MonthlyCharges': 'mean',\n",
    "    'StreamingTV': 'mean',\n",
    "    'StreamingMovies': 'mean',\n",
    "    'PhoneService': 'mean',\n",
    "    'InternetService_DSL': 'mean',\n",
    "    'InternetService_Fiber optic': 'mean'\n",
    "}).rename(columns={\n",
    "    'Churn': 'Taxa Média de Churn',\n",
    "    'MonthlyCharges': 'Receita Média Mensal',\n",
    "    'StreamingTV': 'Uso Médio de TV Streaming',\n",
    "    'StreamingMovies': 'Uso Médio de Filmes Streaming',\n",
    "    'PhoneService': 'Uso Médio de Telefonia',\n",
    "    'InternetService_DSL': 'Uso Médio de DSL',\n",
    "    'InternetService_Fiber optic': 'Uso Médio de Fibra Óptica'\n",
    "})\n",
    "\n",
    "print(\"\\n--- Análise por Cluster ---\")\n",
    "print(cluster_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualização com PCA em 2D ---\n",
    "pca_vis = PCA(n_components=2)\n",
    "X_vis = pca_vis.fit_transform(X_clustering)\n",
    "\n",
    "pca_cluster_df = pd.DataFrame(data=X_vis, columns=['PC1', 'PC2'])\n",
    "pca_cluster_df['Cluster'] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sb.scatterplot(data=pca_cluster_df, x='PC1', y='PC2', hue='Cluster', palette='Set2')\n",
    "plt.title('Visualização dos Clusters com PCA')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Cluster' not in dataframe.columns:\n",
    "    raise ValueError(\"A coluna 'Cluster' não foi encontrada no dataframe. Execute o KMeans antes.\")\n",
    "\n",
    "# Cálculo da análise por cluster\n",
    "cluster_analysis = dataframe.groupby('Cluster').agg({\n",
    "    'Churn': 'mean',                 # Taxa média de churn\n",
    "    'MonthlyCharges': 'mean',       # Receita média mensal\n",
    "    'InternetService_DSL': 'mean',  # Uso de DSL\n",
    "    'PhoneService': 'mean',         # Uso de Telefonia\n",
    "    'StreamingTV': 'mean',          # Uso de TV Streaming\n",
    "    'StreamingMovies': 'mean'       # Uso de Filmes Streaming\n",
    "})\n",
    "\n",
    "# Renomeia as colunas para melhor legibilidade\n",
    "cluster_analysis.rename(columns={\n",
    "    'Churn': 'Taxa Média de Churn',\n",
    "    'MonthlyCharges': 'Receita Média Mensal',\n",
    "    'InternetService_DSL': 'Uso de DSL (%)',\n",
    "    'PhoneService': 'Uso de Telefonia (%)',\n",
    "    'StreamingTV': 'Uso de TV Streaming (%)',\n",
    "    'StreamingMovies': 'Uso de Filmes Streaming (%)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Multiplica os percentuais por 100 para melhor legibilidade\n",
    "cluster_analysis[['Uso de DSL (%)',\n",
    "                  'Uso de Telefonia (%)',\n",
    "                  'Uso de TV Streaming (%)',\n",
    "                  'Uso de Filmes Streaming (%)']] *= 100\n",
    "\n",
    "# Formatação para duas casas decimais\n",
    "cluster_analysis = cluster_analysis.round(2)\n",
    "\n",
    "# Mostra a análise\n",
    "print(\"\\n--- Análise de Clusters ---\")\n",
    "print(cluster_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas numéricas (já escalonadas) usadas para clustering\n",
    "# Excluindo a coluna customerID e variáveis não utilizadas\n",
    "dados_para_pca = dataframe.drop(['customerID', 'Cluster', 'Churn', 'TotalCharges'], axis=1, errors='ignore') # Adicionado 'Churn' e 'TotalCharges' para remoção\n",
    "\n",
    "# Aplicação de PCA para reduzir para 2 dimensões\n",
    "pca = PCA(n_components=2)\n",
    "pca_resultado = pca.fit_transform(dados_para_pca)\n",
    "\n",
    "# Criação de DataFrame com os componentes principais e o cluster\n",
    "df_pca = pd.DataFrame()\n",
    "df_pca['PCA1'] = pca_resultado[:, 0]\n",
    "df_pca['PCA2'] = pca_resultado[:, 1]\n",
    "df_pca['Cluster'] = dataframe['Cluster']\n",
    "\n",
    "# Plot dos clusters no gráfico 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "cores = ['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'brown']\n",
    "\n",
    "for cluster_id in sorted(df_pca['Cluster'].unique()):\n",
    "    cluster_data = df_pca[df_pca['Cluster'] == cluster_id]\n",
    "    plt.scatter(cluster_data['PCA1'], cluster_data['PCA2'],\n",
    "                label=f'Cluster {cluster_id}', alpha=0.6, color=cores[cluster_id % len(cores)])\n",
    "\n",
    "plt.title('Visualização dos Clusters em 2D (PCA)', fontsize=14)\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analysis = cluster_analysis * 100 # Esta linha parece estar duplicada ou causar um erro de escala se executada novamente após a célula 6\n",
    "print(\"\\n--- Estatísticas (%) por Cluster ---\")\n",
    "print(cluster_analysis.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
